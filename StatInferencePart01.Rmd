---
title: "Examining Statistical Inference"
output: 
    html_document:
        keep_md: true
---

*Synopsis:* This report examines principles of statistical inference by investigating simulated random samples from a population.  It was conducted as part of a class assessment for the Johns Hopkins University's ["Statistical Inference"](https://www.coursera.org/course/statinference) offered through Coursera.

## I:  Sample Means Distributions Are Centered at the Population's Mean
This principle enables us to use a sample to approximate the mean of the population from which the sample is drawn.  

To investigate:  

1. We simulate 1000 samples of size 40 from an exponential distribution.  Here, the exponential distribution acts as our population and is parameterized by a rate (lambda) of 0.2.  

```{r}
nosim <- 1000
lambda <- 0.2
expectedValue <- 1/lambda
standardDev <- 1/lambda

SampleMeans <-numeric()

for (i in 1:1000){
        aSample <- rexp(40,lambda)
        temp <- (mean(aSample))
        SampleMeans <- c(SampleMeans, temp)
}

```

2. Next, we compare the empirical and theoretical means of a single sample of 40 exponentials with those of the means of 1000 samples of 40 exponentials.

```{r}
#Show where the distribution is centered at and compare it to the theoretical center of the distribution.

oneSample <- rexp(40,lambda)

par(mfrow=c(1,2),oma=c(1,1,2,1), xpd=FALSE)
hist(oneSample,
     main="1 Sample of 40 Exponentials", cex.main=.8,
     xlab="value",
     col="lightgray")
abline(v=mean(oneSample),col="blue",lwd=2)
abline(v=expectedValue,col="red",lwd=2)
hist(SampleMeans,
     main="Means of 1000 Samples of 40 Exponentials", cex.main=.8,
     xlab="value",
     col="lightgray")
abline(v=mean(SampleMeans),col="blue",lwd=2)
abline(v=expectedValue,col="red",lwd=2)
title(main="Empirical VS Theoretical Center", outer=TRUE)
par(xpd=TRUE)
legend(6.1,300,
       c("Empirical","Theoretical"),
       lty=c(1,1),
       lwd=c(2,2),
       col=c("blue","red"),
       cex=.8)
```

3. From the above plot, we see that while the mean of any one sample can differ from the theoretical (population) mean, the sample means of large numbers of samples are centered on the theoretical mean.  Therefore, we can say that a *sample mean* **approximates** a *population mean*.

##II: Sample Means Variance Decreases With Sample Size
This principle demonstrates that sample means from large samples more accurately reflect the mean of the population from which the samples were drawn.

To investigate:

1. We simulate 1000 samples of sizes 10, 20, 30... through 160 and take the mean of each.

```{r cache=TRUE}
SampleMeans2 <-numeric()

for (n in seq(from=10,to=160,by=10)){
    for (i in 1:1000){
        aSample <- rexp(n,lambda)
        temp <- (mean(aSample))
        SampleMeans2 <- c(SampleMeans2, temp)
    }
}

MatrixMeans <- matrix(SampleMeans2, nrow=1000,ncol=16)
```

2. Next, we take the empirical variance of each of 16 different distributions of sample means and plot it.  This shows that the variance of sample means decreases as the size of the sample increases.

```{r}
#Show how variable it is and compare it to the theoretical variance of the distribution.
variances <- apply(MatrixMeans,2,var)
par(mfrow=c(1,1),oma=c(1,1,1,1), xpd=FALSE)
plot(variances,type="l", col="blue",lwd=2,
     xlab="Sample Size (N)",
     ylab="Sample Means Variance",
     main="Sample Means Variability Decreases With N",cex.main=.8,
     xaxt="n")
axis(1, at=1:16,labels=seq(10,160,by=10))
```

3. Finally, we compare the variance of our sample means of 1000 samples of 40 exponentials to its theoretical variance, verifying that they are close.

```{r}
data.frame(Empirical=var(SampleMeans),Theoretical=((1/lambda)^2/40))
```

##III: Sample Means Distribution is Approximately Normal
This is the Central Limit Theorem in action. By verifying it, we can assume the mean of our sample, if it is large enough, approximates a normal distribution and can be manipulated as such.

To investigate:

1. First, we examine the theoretical distribution of our "population," which, as noted before, follows an exponential distribution.

```{r}
library(ggplot2)
dat0 <- data.frame(
    x = rexp(5000,lambda))
a <- ggplot(dat0, aes(x=x))+geom_histogram(binwidth=1,colour="black",aes(y= ..density.. ))
a <- a + 
    labs(x="Value",y="Density")+
    labs(title="Density Plot of 5000 Random Exponentials")+
    theme_bw()
print(a)
```

2. Next, we compare the distribution of 1000 sample means of increasing size from this exponentially distributed "population."

```{r}
#Show that the distribution is approximately normal.
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - expectedValue) / standardDev #zero the mean and scale
dat <- data.frame(
    x = c(apply(matrix(MatrixMeans[,1]), 1, cfunc, 10),
          apply(matrix(MatrixMeans[,4]), 1, cfunc, 40),
          apply(matrix(MatrixMeans[,16]), 1, cfunc, 160)
    ),
    size = factor(rep(c(10, 40, 160), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(binwidth=.3,colour = "black", aes(y = ..density..)) 
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size) + 
    labs(x="Value",y="Density")+
    labs(title="Sample Means Density Approximates Normal as N Increases")+
    theme_bw()
```

3. From the above plot, we see that the distribution of sample means begins to approximate a normal distribution as the size of the sample increases. 